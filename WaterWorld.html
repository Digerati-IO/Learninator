<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Water World</title>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap-theme.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="css/styles.css">
    <script>
        /**
         * Global world object
         * @type {World}
         */
        var world = world || {};

        var jaxrendered = false;
        function renderJax() {
            if(jaxrendered) {
                return;
            }
            // render markdown
            $(".md").each(function () {
                $(this).html(marked($(this).html()));
            });
            (function () {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
                document.getElementsByTagName("head")[0].appendChild(script);
                jaxrendered = true;
            })();
        }

        /**
         * Create existence!
         */
        function start() {
            world = new WaterWorld();

            renderJax();
        }
    </script>
</head>
<body onload="start();">

<twitch-nav></twitch-nav>

<div class="container-fluid">
    <div class="row">
        <div class="col-md-6">
            <div id="exp" class="md">

### Setup

This is another Deep Q Learning demo with a more realistic and larger setup:

- The **state space** is even larger and continuous: The agent has 30 eye sensors pointing in all directions and in each direction is observes 5 variables: the range, the type of sensed object (green, red), and the velocity of the sensed object. The agent's proprioception includes two additional sensors for its own speed in both x and y directions. This is a total of 152-dimensional state space.
- There are 4 **actions** available to the agent: To apply thrusters to the left, right, up and down. This gives the agent control over its velocity.
- The **dynamics** integrate the velocity of the agent to change its position. The green and red targets bounce around.
- The **reward** awarded to the agent is +1 for making contact with any red target (these are apples) and -1 for making contact with any green target (this is poison).

The optimal strategy of the agent is to cruise around, run away from green targets and eat red targets. What's interesting about this demo is that the state space is so high-dimensional, and also that the sensed variables are agent-relative. They're not just toy x,y coordinates of some fixed number of targets as in previous demo.

            </div>
        </div>
        <div class="col-md-6">
            <div id="flotreward"></div>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h2>
                Water World
                <small>Funsies</small>
            </h2>
            <div class="game-container"></div>
        </div>
    </div>
</div>
<js-includes></js-includes>

<agent-brain-modal></agent-brain-modal>

<link rel="import" href="/templates/js-includes.html">
<link rel="import" href="/templates/twitch-nav.html">
<link rel="import" href="/templates/agent-brain-modal.html">

</body>
</html>