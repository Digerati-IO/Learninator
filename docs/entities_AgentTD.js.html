<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: entities/AgentTD.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: entities/AgentTD.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>var AgentTD = AgentTD || {},
    Agent = Agent || {};

(function (global) {
    "use strict";

    /**
     * Initialize the TD Agent
     * @name AgentTD
     * @extends Agent
     * @constructor
     *
     * @param {Vec} position - The x, y location
     * @param {agentOpts} opts - The Agent options
     * @returns {AgentTD}
     */
    function AgentTD(position, opts) {
        // Reward and Punishment
        this.carrot = +5;
        this.stick = -6;

        // The Agent's actions
        this.actions = [];
        this.actions.push([1, 1]); // Forward?
        this.actions.push([0.8, 1]); // Right?
        this.actions.push([1, 0.8]); // Left?
        this.actions.push([0.5, 0]);
        this.actions.push([0, 0.5]);

        // The number of possible angles the Agent can turn
        this.numActions = this.actions.length;

        // The number of Agent's eyes, each one sees the number of knownTypes
        this.numStates = this.numEyes * this.numTypes;

        Agent.call(this, position, opts);

        // Amount of temporal memory. 0 = agent lives in-the-moment :)
        this.temporalWindow = 1;

        // Size of the network
        this.networkSize = this.numStates * this.temporalWindow + this.numActions * this.temporalWindow + this.numStates;

        /**
         * The value function network computes a value of taking any of the possible actions
         * given an input state.
         *
         * Here we specify one explicitly the hard way but we could also use
         * opt.hidden_layer_sizes = [20,20] instead to just insert simple relu hidden layers.
         * @type {Array}
         */
        this.layerDefs = [];
        this.layerDefs.push({type: 'input', out_sx: 1, out_sy: 1, out_depth: this.networkSize});
        this.layerDefs.push({type: 'fc', num_neurons: 50, activation: 'relu'});
        this.layerDefs.push({type: 'fc', num_neurons: 50, activation: 'relu'});
        this.layerDefs.push({type: 'regression', num_neurons: this.numActions});

        /**
         * The options for the Temporal Difference learner that trains the above net
         * by backpropping the temporal difference learning rule.
         * @type {Object}
         */
        this.tdTrainerOptions = {
            learning_rate: 0.001,
            momentum: 0.0,
            batch_size: 64,
            l2_decay: 0.01
        };

        /**
         * Options for the Brain
         * @type {Object}
         */
        this.brainOpts = {
            numStates: this.numStates,
            numActions: this.numActions,
            temporalWindow: this.temporalWindow,
            experienceSize: 30000,
            startLearnThreshold: 1000,
            gamma: 0.7,
            learningStepsTotal: 200000,
            learningStepsBurnin: 3000,
            epsilonMin: 0.05,
            epsilonTestTime: 0.05,
            layerDefs: this.layerDefs,
            tdTrainerOptions: this.tdTrainerOptions
        };

        this.reset();

        return this;
    }

    AgentTD.prototype = Object.create(Agent.prototype);
    AgentTD.prototype.constructor = Agent;

    /**
     * Agent's chance to act on the world
     */
    AgentTD.prototype.act = function () {
        // Loop through the eyes and check the walls and nearby entities
        for (let e = 0; e &lt; this.numEyes; e++) {
            this.eyes[e].sense(this);
        }

        // Create input to brain
        let inputArray = new Array(this.numEyes * this.numTypes);
        for (let i = 0; i &lt; this.numEyes; i++) {
            inputArray[i * this.numTypes] = 1.0;
            inputArray[i * this.numTypes + 1] = 1.0;
            inputArray[i * this.numTypes + 2] = 1.0;
            if (this.eyes[i].sensedType !== -1) {
                // sensedType is 0 for wall, 1 for food and 2 for poison lets do
                // a 1-of-k encoding into the input array normalize to [0,1]
                inputArray[i * this.numTypes + this.eyes[i].sensedType] = this.eyes[i].sensedProximity / this.eyes[i].maxRange;
            }
        }

        if (!this.worker) {
            // Get action from brain
            this.previousActionIdx = this.actionIndex;
            this.actionIndex = this.brain.forward(inputArray);
            let action = this.actions[this.actionIndex];

            // Demultiplex into behavior variables
            this.rot1 = action[0] * 1;
            this.rot2 = action[1] * 1;

            return this;
        } else {
            this.post('act', inputArray);
        }
    };

    /**
     * The agent learns
     */
    AgentTD.prototype.learn = function () {
        let proximityReward = 0.0,
            forwardReward = 0.0,
            digestionReward = this.digestionSignal,
            reward;
        this.lastReward = this.digestionSignal;

        // Compute the reward
        for (let ei = 0; ei &lt; this.numEyes; ei++) {
            // Agents don't like to see walls, especially up close
            let wallReward = this.eyes[ei].sensedProximity / this.eyes[ei].maxRange;
            proximityReward += this.eyes[ei].sensedType === 0 ? wallReward : 1.0;
        }

        // Calculate the proximity reward
        proximityReward = Math.min(1.0, (proximityReward / this.numEyes) * 2);
        //proximityReward = proximityReward / this.numEyes;
        //proximityReward = Math.min(1.0, proximityReward * 2);

        // Agents like to go straight forward
        if (this.actionIndex === 0 &amp;&amp; proximityReward > 0.75) {
            forwardReward = 0.1 * proximityReward;
        }

        // Agents like to eat good things
        reward = proximityReward + forwardReward + digestionReward;
        this.digestionSignal = 0.0;

        // Pass to brain for learning
        if (!this.worker) {
            this.brain.backward(reward);
            this.pts.push(reward);
        } else {
            this.post('learn', reward);
        }

        return this;
    };

    /**
     * Agent's chance to move in the world
     * @param smallWorld
     */
    AgentTD.prototype.move = function () {
        this.oldPos = this.position.clone();
        this.oldAngle = this.angle;

        //Steer the agent according to outputs of wheel velocities
        let v = new Vec(0, this.radius / 2.0);
        v = v.rotate(this.oldAngle + Math.PI / 2);
            // Positions of wheel 1
        let w1pos = this.position.add(v),
            // Positions of wheel 2
            w2pos = this.position.sub(v);

        let vv = this.position.sub(w2pos);
        vv = vv.rotate(-this.rot1);

        let vv2 = this.position.sub(w1pos);
        vv2 = vv2.rotate(this.rot2);

        let newPos = w2pos.add(vv),
            newPos2 = w1pos.add(vv2);

        newPos.scale(0.5);
        newPos2.scale(0.5);
        let position = newPos.add(newPos2);

        this.position = position;

        this.angle -= this.rot1;
        if (this.angle &lt; 0) {
            this.angle += 2 * Math.PI;
        }

        this.angle += this.rot2;
        if (this.angle > 2 * Math.PI) {
            this.angle -= 2 * Math.PI;
        }

        // Check the world for collisions
        this.world.check(this, false);

        for (let w = 0, wl = this.world.walls.length; w &lt; wl; w++) {
            let wall = this.world.walls[w],
                result = this.world.lineIntersect(this.oldPos, this.position, wall.v1, wall.v2, this.radius);
            if (result) {
                this.collisions.unshift(wall);
            }
        }

        // Go through and process what we ate/hit
        let minRes = false,
            result;
        for (let i = 0; i &lt; this.collisions.length; i++) {
            // Nom or Gnar
            if (this.collisions[i].type === 1 || this.collisions[i].type === 2) {
                for (let w = 0, wl = this.world.walls.length; w &lt; wl; w++) {
                    let wall = this.world.walls[w];
                    result = this.world.lineIntersect(this.position, this.collisions[i].position, wall.v1, wall.v2, this.radius);
                    if (result) {
                        if (!minRes) {
                            minRes = result;
                        } else {
                            // Check if it's closer
                            if (result.vecX &lt; minRes.vecX) {
                                // If yes, replace it
                                minRes = result;
                            }
                        }
                    }
                }

                if (!minRes) {
                    //let rewardBySize = this.carrot + (this.collisions[i].radius / 100),
                    //    stickBySize = this.stick - (this.collisions[i].radius / 100);
                    //this.digestionSignal += (this.collisions[i].type === 1) ? rewardBySize : stickBySize;
                    this.digestionSignal += (this.collisions[i].type === 1) ? this.carrot : this.stick;
                    this.collisions[i].cleanUp = true;
                }
            } else if (this.collisions[i].type === 3 || this.collisions[i].type === 4) {
                // Agent
                //console.log('Watch it ' + this.collisions[i].name);
            } else if (this.collisions[i].type === 0) {
                // Wall
                this.position = this.oldPos.clone();
                this.position.vx = 0;
                this.position.vy = 0;
            }
        }

        // Handle boundary conditions.. bounce Agent
        let top = this.world.height - (this.world.height - this.radius),
            bottom = this.world.height - this.radius,
            left = this.world.width - (this.world.width - this.radius),
            right = this.world.width - this.radius;
        if (this.position.x &lt; left) {
            this.position.x = left;
            this.position.vx = 0;
            this.position.vy = 0;
        }

        if (this.position.x > right) {
            this.position.x = right;
            this.position.vx = 0;
            this.position.vy = 0;
        }

        if (this.position.y &lt; top) {
            this.position.y = top;
            this.position.vx = 0;
            this.position.vy = 0;
        }

        if (this.position.y > bottom) {
            this.position.y = bottom;
            this.position.vx = 0;
            this.position.vy = 0;
        }

        this.direction = Utility.getDirection(this.angle);

        if (this.useSprite) {
            this.sprite.position.set(this.position.x, this.position.y);
            this.sprite.rotation = this.angle * 0.01745329252;
        }

        return this;
    };

    AgentTD.prototype.reset = function () {
        let _this = this;
        if (!this.worker) {
            this.brain = new TDBrain(this.brainOpts);
        } else {
            this.post = function (cmd, input) {
                this.brain.postMessage({target: 'TD', cmd: cmd, input: input});
            };

            this.brain = new Worker('js/entities/TDBrain.js');
            this.brain.onmessage = function (e) {
                let data = e.data;
                switch (data.cmd) {
                    case 'init':
                        if (data.msg === 'complete') {

                        }
                        break;
                    case 'act':
                        if (data.msg === 'complete') {
                            _this.previousActionIdx = _this.actionIndex;
                            _this.actionIndex = data.input;
                            let action = _this.actions[_this.actionIndex];

                            // Demultiplex into behavior variables
                            _this.rot1 = action[0] * 1;
                            _this.rot2 = action[1] * 1;

                            _this.move();
                            _this.learn();
                        }
                        break;
                    case 'learn':
                        if (data.msg === 'complete') {
                            _this.pts.push(parseFloat(data.input));
                            _this.avgReward = parseFloat(data.input);
                        }
                        break;
                    case 'load':
                        if (data.msg === 'complete') {
                            _this.epsilon = parseFloat(data.input);
                        }
                        break;
                    default:
                        console.log('Unknown command: ' + data.cmd + ' message:' + data.msg);
                        break;
                }
            };

            this.post('init', this.brainOpts);
        }
    };

    global.AgentTD = AgentTD;

}(this));

</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Agent.html">Agent</a></li><li><a href="AgentGA.html">AgentGA</a></li><li><a href="AgentRLDQN.html">AgentRLDQN</a></li><li><a href="AgentRLTD.html">AgentRLTD</a></li><li><a href="AgentTD.html">AgentTD</a></li><li><a href="Bitmap.html">Bitmap</a></li><li><a href="BruteCD.html">BruteCD</a></li><li><a href="Button.html">Button</a></li><li><a href="Camera.html">Camera</a></li><li><a href="Cell.html">Cell</a></li><li><a href="Chromosome.html">Chromosome</a></li><li><a href="CollisionDetector.html">CollisionDetector</a></li><li><a href="datGUI.html">datGUI</a></li><li><a href="DeterministPG.html">DeterministPG</a></li><li><a href="Display.html">Display</a></li><li><a href="DPAgent.html">DPAgent</a></li><li><a href="DQNAgent.html">DQNAgent</a></li><li><a href="Entity.html">Entity</a></li><li><a href="EntityRLDQN.html">EntityRLDQN</a></li><li><a href="ESPNet.html">ESPNet</a></li><li><a href="ESPTrainer.html">ESPTrainer</a></li><li><a href="Eye.html">Eye</a></li><li><a href="GATrainer.html">GATrainer</a></li><li><a href="Graph.html">Graph</a></li><li><a href="Grid.html">Grid</a></li><li><a href="GridCD.html">GridCD</a></li><li><a href="GridWorld.html">GridWorld</a></li><li><a href="HeCubex.html">HeCubex</a></li><li><a href="Hex.html">Hex</a></li><li><a href="HexGrid.html">HexGrid</a></li><li><a href="HexWorld.html">HexWorld</a></li><li><a href="Interactions.html">Interactions</a></li><li><a href="Map.html">Map</a></li><li><a href="Mat.html">Mat</a></li><li><a href="Maze.html">Maze</a></li><li><a href="MazeWorld.html">MazeWorld</a></li><li><a href="Menu.html">Menu</a></li><li><a href="Player.html">Player</a></li><li><a href="Point.html">Point</a></li><li><a href="PuckWorld.html">PuckWorld</a></li><li><a href="QuadCD.html">QuadCD</a></li><li><a href="QuadTree.html">QuadTree</a></li><li><a href="RecurrentReinforceAgent.html">RecurrentReinforceAgent</a></li><li><a href="RewardGraph.html">RewardGraph</a></li><li><a href="SimpleReinforceAgent.html">SimpleReinforceAgent</a></li><li><a href="Solver.html">Solver</a></li><li><a href="TDAgent.html">TDAgent</a></li><li><a href="Vec.html">Vec</a></li><li><a href="Wall.html">Wall</a></li><li><a href="WaterWorld.html">WaterWorld</a></li><li><a href="WaterWorldEX.html">WaterWorldEX</a></li><li><a href="WaterWorldGA.html">WaterWorldGA</a></li><li><a href="Window.html">Window</a></li><li><a href="World.html">World</a></li><li><a href="%257Bobject%257D%2520input.html">{object} input</a></li></ul><h3>Global</h3><ul><li><a href="global.html#clear">clear</a></li><li><a href="global.html#clone">clone</a></li><li><a href="global.html#divide">divide</a></li><li><a href="global.html#EZGUI">EZGUI</a></li><li><a href="global.html#findByAngle">findByAngle</a></li><li><a href="global.html#findByName">findByName</a></li><li><a href="global.html#findInsertNode">findInsertNode</a></li><li><a href="global.html#findOverlappingNodes">findOverlappingNodes</a></li><li><a href="global.html#initSensors">initSensors</a></li><li><a href="global.html#insert">insert</a></li><li><a href="global.html#isAndroid">isAndroid</a></li><li><a href="global.html#isChrome">isChrome</a></li><li><a href="global.html#isFirefox">isFirefox</a></li><li><a href="global.html#isGecko">isGecko</a></li><li><a href="global.html#isIE">isIE</a></li><li><a href="global.html#isIOS">isIOS</a></li><li><a href="global.html#isIPad">isIPad</a></li><li><a href="global.html#isIPhone">isIPhone</a></li><li><a href="global.html#isIPod">isIPod</a></li><li><a href="global.html#isKindle">isKindle</a></li><li><a href="global.html#isMobile">isMobile</a></li><li><a href="global.html#isOpera">isOpera</a></li><li><a href="global.html#isSafari">isSafari</a></li><li><a href="global.html#isTablet">isTablet</a></li><li><a href="global.html#isTV">isTV</a></li><li><a href="global.html#isWebKit">isWebKit</a></li><li><a href="global.html#resetSensors">resetSensors</a></li><li><a href="global.html#retrieve">retrieve</a></li><li><a href="global.html#Utility">Utility</a></li><li><a href="global.html#whoami">whoami</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.3.3</a> on Thu Dec 03 2015 10:30:02 GMT-0800 (PST)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
